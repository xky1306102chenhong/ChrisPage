---
layout: post  
title: 针对大规模图像识别的特深的深度卷积神经网络  
---

{{ page.title }}
================

<p class="meta">{{ page.date | date_to_string }} - Changsha</p>  

> _翻译自[VGG](https://arxiv.org/abs/1409.1556)_

+ 0.摘要  
在本文的工作中，我们研究在大规模图像识别中卷积网络深度对识别准确度（accuracy）的影响。<font color="red">我们的
主要贡献是一个全面的(对增加深度的网络)的评估，这种网络使用很小(3x3)的卷积过滤器，这种使用这种
过滤器的网络显示，当网络深度深至16-19层时可以在现有(prior-art)配置上取得极大的提升。</font>这些发现是我
们在 ImageNet Challenge 2014 提交代码的基础，在该挑战赛中，我们的团队取得了定位（localisation）
第一和分类（classification）第二的名次。我们也展示了我们的表征（representations）很好地泛
化到其他数据集上，在其他数据集上取得了最先进的（state-of-the-art）结果。我们公开了两种性能最
好的卷积神经网络模型去促进(关于深度可视表征（deep visual representations）在计算机视觉中的
使用的)进一步研究。
+ 1.介绍  
卷积神经网络近来在大规模图像和视频识别中取得了巨大的成功(Krizhevsky et al., 2012; Zeiler &
Fergus, 2013; Sermanet et al., 2014; Simonyan & Zisserman, 2014)，使这个成功实现的是
大规模公开的图像库，如ImageNet，和高性能的计算系统，如GPUs和大规模分布式集群。特别地，the ImageNet Large-ScaleVisual Recognition Challenge (ILSVRC)
在深度可视识别架构的发展中扮演了重要的角色，ILSVRC是几代大规模图像识别系统的测试平台，从高维浅层
特征编码到深度卷积神经网络。  
随着卷积神经网络成为计算机视觉领域的日常用品，许多人竞先（in a bid）尝试提升Krizhevsky的原始
架构，为了获得更好的准确率。 比如，ILSVRC-2013性能最好的提交（submissions）在一层卷积层使用
更小的接受窗口和更小的步长。另一项提升卷积神经网络性能的做法是在整个图片和多个规模上密集地训练
网络和测试网络。<font color="red">在本文中，我们提出卷积神经网络架构设计的另一个重要方面-深度。
为此（to this end），我们先固定架构（architecture）的其他参数，然后通过添加更多的卷积层来慢慢
地增加网络深度。</font>  
最后，我们提出了准确率更好的卷积神经网络架构，这个网络架构不仅在ILSVRC的分类和定位任务上实现了
最先进的准确度，而且也应用到了其他的图像识别数据集上，在其他数据集上也取得了优异（excellent）表现，
甚至只是作为相对简单网络（pipelines）的一部分（比如，使用没有微调的线性SVM的深度特征分类）。我们
公开了两种性能最好的模型去促进进一步的研究。<font color="red">本文剩下的部分按如下组织。在第二部分（Sect.2），描述
我们的网络配置。在第三部分（Sect.3）陈述图像分类训练和评估的细节，然后四部分（Sect.4）
在ILSVRC分类任务中比较网络配置。第五部分（Sect.5）总结全文。为了完整性，我们也在附录A中描述和评估
我们ILSVRC-2014对象定位系统，在附录B中讨论深度特征到其他数据集的泛化。最后，在附录C中给出论文修改清单。</font>  
+ 2.网络配置  
为了在公平的环境中（in a fair setting）来测量通过增加网络深度带来的提升，所有我们的卷积网络层配置
都使用同样的原则设计，都受到 Ciresan et al. (2011); Krizhevsky et al. (2012)的影响。<font color="red">在本部分，
我们首先描述一个我们的卷积网络配置的通用（generic）布局（Sect.2.1），然后说明（detail）评估中使用的
具体配置（Sect.2.2）。在Sect.2.3，讨论我们的设计选择然后将我们的设计选择与现有技术进行比较。</font>  
+ 2.1 架构  
在训练期间，<font color="red">输入到我们的卷积网络的是固定大小的224x224RGB图片。我们所做的唯一预处理
是减去平均RGB值，这个RGB平均值是训练集中每个像素点的RGB平均。图片穿过一系列的卷积层，在这些卷积层中
我们使用带特小接受域的过滤器:3x3（3x3是能得到左右、上下、中信息的最小的尺寸）。在其中的一种配置中，
我们也使用了1x1的卷积过滤器，这样的过滤器可以看作是输入通道的线性变化（其次是（followed by）非线性）。
卷积步长固定为1个像素；卷积层的空间填充使得（is such that）在卷积之后空间解析度被保留下来，换句话说（i.e.）
对于卷积核是3x3的卷积层，空间填充取1个像素。空间池化采用的是五个最大池化层，这些池化层跟随一些卷积层后面
（不是所有的卷积层后都会接最大池化）。最大池化采取2x2像素窗口，步长为2。</font>  
一系列卷积层（不同的架构有不同的卷积深度）后接了3个全连接层：头两层每层都有4096个通道，第三层执行1000个
ILSVRC分类，因此有1000个通道（一个通道一个类别）。最后一层是soft-max层。在本文所有的网络中，全连接层的配置
都一样。  
+ 2.2 配置  
本文中评估（evaluated）的卷积神经网络配置一列一列的列出在表1（Table 1）中。接下来（In the following），
我们将通过网络的名字（A-E），引用他们。所有的配置都遵循（follow）在Sect.2.1中陈述的通用设计，只是深度从11
个权重层（8个卷积层和3个全连接层，A网络配置）到19个权重层（16个卷积层和3个全连接层，E网络配置）的区别。卷积
层的宽度（通道的数量）是相当小（rather small），从开始第一层的64通道，然后每经过一个max-pooling层后，增加
2倍，直到到达512通道。  
在表2中，我们报告了每种配置的参数数量。尽管深度极深，但是我们网络的权重数量并没有比{大卷积层宽度和大接受域的浅
层网络的权重数量（(Sermanet et al., 2014)有144M权重）}更大。  
+ 2.3 讨论  
我们的网络配置和在ILSVRC-2012 (Krizhevsky et al., 2012) and ILSVRC-2013 比赛 (Zeiler & Fergus, 2013; Sermanet et al., 2014)
表现优异的网络有很大的不同。我们没有在第一个卷积层使用相对大的接受域（比如，在 (Krizhevsky et al., 2012)中使用
4步长的11x11卷积核，或者在 (Zeiler & Fergus, 2013; Sermanet et al., 2014)中使用2步长7x7的卷积核），而是在所有的卷积层使用非常
小的接受域3x3，这个卷积核与输入图片的每个像素卷积（步长为1个像素）。显而易见的是两个3x3的卷积层（之间没有池化层）相当于5x5的
接受域；三个这样的卷积层相当于7x7的接受域。我们使用3个3x3的卷积层来替代单个7x7卷积层到底有什么好处？<font color="red">
第一，我们合并（incorporate）了3个非线性整流层（rectification）来代替单一的非线性整流层，这使得判定函数（decision function）
更有分辨能力（more discriminative）。第二，我们减少了参数数量：假设三层3x3卷积层的输入和输出通道是C，那么它的
有3x(3x3xCxC)=27C<sup>2</sup>个权重(没有计算偏置量)；但是，单个7x7的卷积层需要7<sup>2</sup>C<sup>2</sup>=49C<sup>2</sup>,
换句话说，单层对比多了81%的参数。这个可以认为是在7x7的卷积核实施正则化，这个正则化要求单个7x7的卷积核通过3x3的卷积核来分解
（其间注入非线性）。</font>

Table 1：卷积网络配置（按列）。配置的深度从左边（A）增加到右边（E），增加更多的层（增加的层用粗体表示）。卷积层的参数被表示
成“conv(卷积核大小)-(通道数)”。为了简洁，ReLU激活函数没有列出。

![avatar](/images/posts/2019-03-05/vgg_config.png)

![avatar](/images/posts/2019-02-21/VGG_Configuration.png)

