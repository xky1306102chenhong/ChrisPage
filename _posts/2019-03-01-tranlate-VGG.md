---
layout: post  
title: 针对大规模图像识别的特深的深度卷积神经网络  
---

{{ page.title }}
================

<p class="meta">{{ page.date | date_to_string }} - Changsha</p>  

> _翻译自[VGG](https://arxiv.org/abs/1409.1556)_

专有名词的翻译：
+ receptive field：接受域
+ multiple crops：多裁剪图片

+ 0.摘要  
在本文的工作中，我们研究在大规模图像识别中卷积网络深度对识别准确度（accuracy）的影响。<font color="red">我们的
主要贡献是一个全面的(对增加深度的网络)的评估，这种网络使用很小(3x3)的卷积过滤器，这种使用这种
过滤器的网络显示，当网络深度深至16-19层时可以在现有(prior-art)配置上取得极大的提升。</font>这些发现是我
们在 ImageNet Challenge 2014 提交代码的基础，在该挑战赛中，我们的团队取得了定位（localisation）
第一和分类（classification）第二的名次。我们也展示了我们的表征（representations）很好地泛
化到其他数据集上，在其他数据集上取得了最先进的（state-of-the-art）结果。我们公开了两种性能最
好的卷积神经网络模型去促进(关于深度可视表征（deep visual representations）在计算机视觉中的
使用的)进一步研究。
+ 1.介绍  
卷积神经网络近来在大规模图像和视频识别中取得了巨大的成功(Krizhevsky et al., 2012; Zeiler &
Fergus, 2013; Sermanet et al., 2014; Simonyan & Zisserman, 2014)，使这个成功实现的是
大规模公开的图像库，如ImageNet，和高性能的计算系统，如GPUs和大规模分布式集群。特别地，the ImageNet Large-ScaleVisual Recognition Challenge (ILSVRC)
在深度可视识别架构的发展中扮演了重要的角色，ILSVRC是几代大规模图像识别系统的测试平台，从高维浅层
特征编码到深度卷积神经网络。  
随着卷积神经网络成为计算机视觉领域的日常用品，许多人竞先（in a bid）尝试提升Krizhevsky的原始
架构，为了获得更好的准确率。 比如，ILSVRC-2013性能最好的提交（submissions）在一层卷积层使用
更小的接受窗口和更小的步长。另一项提升卷积神经网络性能的做法是在整个图片和多个规模上密集地训练
网络和测试网络。<font color="red">在本文中，我们提出卷积神经网络架构设计的另一个重要方面-深度。
为此（to this end），我们先固定架构（architecture）的其他参数，然后通过添加更多的卷积层来慢慢
地增加网络深度。</font>  
最后，我们提出了准确率更好的卷积神经网络架构，这个网络架构不仅在ILSVRC的分类和定位任务上实现了
最先进的准确度，而且也应用到了其他的图像识别数据集上，在其他数据集上也取得了优异（excellent）表现，
甚至只是作为相对简单网络（pipelines）的一部分（比如，使用没有微调的线性SVM的深度特征分类）。我们
公开了两种性能最好的模型去促进进一步的研究。<font color="red">本文剩下的部分按如下组织。在第二部分（Sect.2），描述
我们的网络配置。在第三部分（Sect.3）陈述图像分类训练和评估的细节，然后四部分（Sect.4）
在ILSVRC分类任务中比较网络配置。第五部分（Sect.5）总结全文。为了完整性，我们也在附录A中描述和评估
我们ILSVRC-2014对象定位系统，在附录B中讨论深度特征到其他数据集的泛化。最后，在附录C中给出论文修改清单。</font>  
+ 2.网络配置  
为了在公平的环境中（in a fair setting）来测量通过增加网络深度带来的提升，所有我们的卷积网络层配置
都使用同样的原则设计，都受到 Ciresan et al. (2011); Krizhevsky et al. (2012)的影响。<font color="red">在本部分，
我们首先描述一个我们的卷积网络配置的通用（generic）布局（Sect.2.1），然后说明（detail）评估中使用的
具体配置（Sect.2.2）。在Sect.2.3，讨论我们的设计选择然后将我们的设计选择与现有技术进行比较。</font>  
+ 2.1 架构  
在训练期间，<font color="red">输入到我们的卷积网络的是固定大小的224x224RGB图片。我们所做的唯一预处理
是减去平均RGB值，这个RGB平均值是训练集中每个像素点的RGB平均。图片穿过一系列的卷积层，在这些卷积层中
我们使用带特小接受域的过滤器:3x3（3x3是能得到左右、上下、中信息的最小的尺寸）。在其中的一种配置中，
我们也使用了1x1的卷积过滤器，这样的过滤器可以看作是输入通道的线性变化（其次是（followed by）非线性）。
卷积步长固定为1个像素；卷积层的空间填充使得（is such that）在卷积之后空间解析度被保留下来，换句话说（i.e.）
对于卷积核是3x3的卷积层，空间填充取1个像素。空间池化采用的是五个最大池化层，这些池化层跟随一些卷积层后面
（不是所有的卷积层后都会接最大池化）。最大池化采取2x2像素窗口，步长为2。</font>  
一系列卷积层（不同的架构有不同的卷积深度）后接了3个全连接层：头两层每层都有4096个通道，第三层执行1000个
ILSVRC分类，因此有1000个通道（一个通道一个类别）。最后一层是soft-max层。在本文所有的网络中，全连接层的配置
都一样。  
+ 2.2 配置  
本文中评估（evaluated）的卷积神经网络配置一列一列的列出在表1（Table 1）中。接下来（In the following），
我们将通过网络的名字（A-E），引用他们。所有的配置都遵循（follow）在Sect.2.1中陈述的通用设计，只是深度从11
个权重层（8个卷积层和3个全连接层，A网络配置）到19个权重层（16个卷积层和3个全连接层，E网络配置）的区别。卷积
层的宽度（通道的数量）是相当小（rather small），从开始第一层的64通道，然后每经过一个max-pooling层后，增加
2倍，直到到达512通道。  
在表2中，我们报告了每种配置的参数数量。尽管深度极深，但是我们网络的权重数量并没有比{大卷积层宽度和大接受域的浅
层网络的权重数量（(Sermanet et al., 2014)有144M权重）}更大。  
+ 2.3 讨论  
我们的网络配置和在ILSVRC-2012 (Krizhevsky et al., 2012) and ILSVRC-2013 比赛 (Zeiler & Fergus, 2013; Sermanet et al., 2014)
表现优异的网络有很大的不同。我们没有在第一个卷积层使用相对大的接受域（比如，在 (Krizhevsky et al., 2012)中使用
4步长的11x11卷积核，或者在 (Zeiler & Fergus, 2013; Sermanet et al., 2014)中使用2步长7x7的卷积核），而是在所有的卷积层使用非常
小的接受域3x3，这个卷积核与输入图片的每个像素卷积（步长为1个像素）。显而易见的是两个3x3的卷积层（之间没有池化层）相当于5x5的
接受域；三个这样的卷积层相当于7x7的接受域。我们使用3个3x3的卷积层来替代单个7x7卷积层到底有什么好处？<font color="red">
第一，我们合并（incorporate）了3个非线性整流层（rectification）来代替单一的非线性整流层，这使得判定函数（decision function）
更有分辨能力（more discriminative）。第二，我们减少了参数数量：假设三层3x3卷积层的输入和输出通道是C，那么它的
有3x(3x3xCxC)=27C<sup>2</sup>个权重(没有计算偏置量)；但是，单个7x7的卷积层需要7<sup>2</sup>C<sup>2</sup>=49C<sup>2</sup>,
换句话说，单层对比多了81%的参数。这个可以认为是在7x7的卷积核实施正则化，这个正则化要求单个7x7的卷积核通过3x3的卷积核来分解
（其间注入非线性）。</font>  
Table 1：卷积网络配置（按列）。配置的深度从左边（A）增加到右边（E），增加更多的层（增加的层用粗体表示）。卷积层的参数被表示
成“conv(卷积核大小)-(通道数)”。为了简洁，ReLU激活函数没有列出。  
![avatar](/images/posts/2019-03-05/vgg_config.png)  
![avatar](/images/posts/2019-02-21/VGG_Configuration.png)  
Table 2：参数数量（单位：百万）  
![avatar](/images/posts/2019-03-05/vgg_parameter_num.png)  
包含1x1的卷积层（表1，配置C）是一种在没有影响卷积层的接受域下增加决策函数的非线性。尽管在我们的实例中1x1的卷积本质上是
在同样维度（输入通道数量和输出通道数量是一样的）的空间上的线性投影，但是整流函数引入了额外的非线性。应该注意的是1x1的卷积层
近来被用在Lin以及其他(et al.) (2014)提出的“网络中的网络”架构中。    
Ciresan等人(2011)之前就使用过小尺寸的卷积核， 但是他们的网络比我们的浅太多，并且他们没在大规模ILSVRC数据集上测试过。
Goodfellow等人(2014)应用深度卷积网络（11 个权重层）到门牌号的识别任务中，结果显示增加网络深度可以得到更好的表现。
GoogLeNet(Szegedy等人, 2014)，ILSVRC-2014分类任务表现最佳（top-performing）的参赛作品（entry），和我们的工作相互独立地被开发
出来，但是两者非常相似，因为GoogLeNet也是基于极深的卷积网络（22个权重层）和很小的卷积核（除了3x3外，他们也使用1x1
和5x5的卷积核）。但是他们的网络拓扑比我们的更加复杂，为了减少计算量，在第一层中，特征图（通道）的空间解析度被减少的更严重。
正如Sect. 4.5将要展示的（As will be shown in Sect. 4.5）,在单网络分类准确度方面（in terms of），我们的模型
优于（outperforming）Szegedy(2014)等。
+ 3.分类框架  
在之前的部分，我们陈述了网络配置的细节。在这个部分，我们描述分类卷积网络的训练和测试（evaluation）。
+ 3.1 训练  
卷积网络的训练流程大体上遵循了Krizhevsky等人（2012）（除了从多尺度（multi-scale）训练图片中裁剪采样输入，后面会解释）。
换句话说（namely），<font color="red">通过优化多项逻辑回归目标函数来训练网络，这个优化使用带动量的小批次梯度下降法（基于反向传播（LeCun等人，1989））。
批大小设置为256，动量（momentum）设置为0.9。用权重退化（weight decay）来正则化训练（L<sub>2</sub>惩罚乘数设置为5x10<sup>-4</sup>）
并在头两个全连接层设置dropout正则化（dropout率设为0.5）。学习率初始化为10<sup>-2</sup>，当验证集的准确率停止提升，学习率就以10为因子减少。
总共，学习率减少了3次，并且迭代370K次（74轮）后学习停止。</font>我们猜想（conjecture），相对于（Krizhevsky等人，2012）的网络尽管我们
网络的参数更多和网络更深，但是需要更少的训练轮数来收敛网络，这是因为(a)更深的深度和更小的卷积核给与了隐形的正则化；(b)
某些层的预初始化。  
网络权重的初始化是很重要的，因为深度网络梯度的不稳定性，差的初始化会导致停止学习。为了避免这个问题，我们以训练配置A（表1）为开始，
它足够浅以至于可以用随机初始化来训练。接下来，当训练更深的网络的时候，我们用配置A的网络权重来初始化头四个卷积层和最后三个全连接层
（中间层采用随机初始化）。我们没有为预初始化的层减少学习率，允许它在学习的过程中改变。对于随机初始化（可以使用的地方），我们
从以0为均值，10<sup>-2</sup>为方差的正态分布中采样权重。偏置量初始化为0。值得一提的是（ It is worth noting that）在论文提交后我们发现
没有预训练，而是用Glorot & Bengio (2010）的随机初始化流程来初始化权重也是可行的。  
为了获得固定大小224x224的网络输入图片，这些图片从重新缩放的训练图片中随机裁剪（每张图片每次SGD迭代裁剪一次）。为了进一步增广训练集，裁剪出
来的图片要经随机水平移动（horizontal flipping）和随机RBG色移（RGB color shift）(Krizhevsky et al., 2012)。
接下来解释训练图片的重新缩放。  
**训练图片大小** 令S为一各向同性重新缩放（isotropically-rescaled）的训练图片的最小边，网络的输入裁剪自各向同性缩放的训练图片
（我们也用S做为训练的尺寸）。当裁剪尺寸固定为224x224时，原则上S能取任何不小于224的值：当S=224，裁剪出的图片包含了整张图片的统计资料，
完整横跨了训练图片的最小边；当$S \gg 224$时，裁剪出的图片只对应了整张图片的一小部分，包含一个小对象或对象的一部分。  
为了设置S的大小，我们考虑了两种方法。第一个方法时固定S，这个方法用于单尺度训练（值得注意的是，采样裁剪内的图片内容仍可表示多尺度图片统计数据）。
在我们的实验中，我们测试（evaluated）的模型它是用两种固定尺度训练：S=256（S=256被广泛地应用在现有技术中(Krizhevsky et al., 2012; Zeiler & Fergus, 2013; Sermanet et al., 2014)）和
S=384。若由一个卷积网络配置，我们先用S=256训练。为了加速S=384网络的训练，我们用预训练S=256的网络权重来初始化，并且使用更小的初始学习率10<sup>-3</sup>。
第二种设置S的方法是多尺度训练，在这个方法中每张训练图片都是独立的被（从某个范围[S<sub>min</sub>, S<sub>max</sub>]中采样的S）缩放（
我们的S<sub>min</sub>取256，S<sub>max</sub>取512）。因为图片中的目标可以有不同的大小，这个方法有利于在训练的时候将这个因素考虑进去。
这个方法也可以认为是通过尺度抖动（scale jittering）来增广训练集，在尺度抖动的方法中，一个单一的模型被训练成可以识别跨越一定尺度的目标。
出于速度的考虑，我们通过微调同样配置的单尺度模型的所有层来训练多尺度模型，这里单尺度我们固定S=384来预训练。  
+ 3.2 测试  
在测试的时候，若有一个训练好的网络和输入图片，它是按以下方式分类的。首先，图片被同向缩放到预定义的最小边，最小边定义为Q（我们也用Q来表示测试尺度）。
我们指出Q没有必要一定等于训练尺度S（正如Sect.4所展示的，一个S用几个Q值可以提升性能）。
然后，以类似于（Sermanet等人，2014）的方式将网络密集地应用于重新缩放的测试图像上。
换句话说，<font color="red">全连接层首先转化为卷积层（头一个全连接层变为一个7x7的卷积层，最后两个全连接层变为两个1x1的卷积层）。
然后将得到的全卷积网络应用于整个（未剪切的）图像。
结果是一个(带有通道数等于类别数的)类别得分图和一个取决于输入图片尺寸的可变的空间分辨率(resolution)。
最后，为了得到图片的一个固定大小的类别得分的向量，类别得分图(class score map)在空间上被平均了(和池化)。</font>
我们也通过图片的水平移动来增广测试集；将原始图像和翻转图像的soft-max类后验平均化以获得图像的最终分数。  
因为全卷积网络应用到整张图片，所以在测试到时候没有必要采样多重裁剪(Krizhevsky et al., 2012)，
由于多重裁剪需要网络为了每个裁剪(crop)重新计算会导致低效率。
同时，使用大的裁剪集，如Szegedy et al. (2014）的做法，可以提升准确度，因为与全卷积网络相比，它得到输入图片的精确采样。
此外，由于不同的卷积边界条件，多裁剪测试和集中测试可以互补：当将卷积网络应用到裁剪图片上时，被卷积的特征图以0来填充（padded），
而集中测试中，同样一张裁剪图片它的填充来自这张图片本身（由于卷积核池化），这会大大地（substantially）增加整个网络的接受域，
这也就可以获得更多的上下文信息。而我们认为在实践中多裁剪图片增加的计算时间不能证明准确性的潜在增加，
为了参考，我们还评估了我们的网络，每个尺寸使用50个裁剪图片 (5×5 regular grid with 2 ﬂips), for a total of 150 crops over 3 scales, which is comparable to 144 crops over 4 scales used by Szegedy et al. (2014)。（此处待翻译）  
+ 3.3 实现细节  
