---
layout: post  
title: 并行化卷积神经网络的一种奇妙技巧  
---

{{ page.title }}
================

<p class="meta">{{ page.date | date_to_string }} - Changsha</p>  

> _翻译自https://arxiv.org/abs/1404.5997_

+ model part：模型的一部分
+ batch size：批大小

+ 0.摘要  
我们提出一种新的跨多GPU的并行化卷积神经网络训练的方法。
当应用于现代卷积神经网络时，该方法比所有替代方案明显地可以更好地扩展(scales)。
+ 1.简介  
这是一个简短的说明，介绍了一种新的方法来以随机梯度下降（SGD）并行化卷积神经网络的训练。
我提出了该算法的两种变体。
第一个种完美地模拟了随机梯度下降法在单核上的同步执行，而第二种变体引入了近似，所以它就不是在完美地模拟随机梯度下降在单核上的同步执行，但是不管怎么样在实践中表现地很好。
+ 2.现有方法  
卷积神经网络是一个在大数据集上训练的大模型。所以明显有以下两种方法来并行化训练：  
  + 跨模型纬度，不同的workers训练模型的不同部分。
  + 跨数据纬度，不同的workers基于不同的数据样本训练。
这两种方式分别被称为模型并行和数据并行。  
在模型并行中，任何时候一个worker上训练的模型的一部分(神经元活动的子集)需要在其他worker上训练的模型的一部分的<font color="red">输出，两个worker必须同步<font>。
相比之下，在数据并行中，为了确保他们是在训练一个连续的模型，<font red="color">workers之间必须同步模型参数(参数梯度)<font>。  
通常，我们应该利用并行的所有纬度。
这两种方案都不比先前的方案好。
但是我们利用每个方案的相对程度应该通过模型架构来决定。
特别地，当每个神经元活动的计算量都很大的时候，模型并行是高效的(因为神经元活动是通信的单元)，而当每个权重当计算量很大的时候，数据并行是高效的(因为权重是通信单元)。  
影响所有这一切(all of this)的另一个因素是批大小。
如果我们愿意增加批大小(因为权重同步是每个批次执行一次)，我们可以使数据并行变得任意高效。
但是非常大的批大小对在该批次上的SGD的收敛速率和最终解决的质量有负面影响。
所以这里我把批大小设置为几百个或几千个样本。
+ 3.一些观察  
现代卷积神经网络由两种属性非常不同的层组成。
  + 卷积层累计大约90-95%的计算量，5%的参数，并且具有很大的表征性。
  + 全连接层大约有5-10%的计算量，95%的参数，表征能力较弱。
了解了这一点以后，我们就会很自然的想是否应该用不同的方法来并行这两种层。
特别地，数据并行适合卷积层而模型并行适合全连接层。  
这正是我所提出的方法。
在本文的内容中，我将更详细地解释该方案，并提到几个不错的属性。
+ 4.提出的算法
我提出的并行化训练卷积神经网络的方法，主要是在卷积层使用数据并行，在全连接层使用模型并行。
图1展示了K个workers上的该算法。  
![avatar](/images/posts/2019-03-14/parallelize-cnn-1.png)